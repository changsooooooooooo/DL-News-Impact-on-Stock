{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5fe3393",
   "metadata": {},
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7cd4b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import BertModel, DistilBertModel\n",
    "# import kobert_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6ef7fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Administrator\\\\Desktop\\\\Work\\\\2. 인공지능리서치AIR\\\\1. source code'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5fd2fd",
   "metadata": {},
   "source": [
    "## save pre-trained kobert model (2021.07.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6f93228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, 'pretrained_kobert_20210730.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d73904",
   "metadata": {},
   "source": [
    "# data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03859cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"C:/Users/Administrator/Desktop/Work/2. 인공지능리서치AIR/2. data sets/1. input data\"\n",
    "file_name1 = \"(1차)13,500건.xlsx\"\n",
    "os.path.join(data_path, file_name1)\n",
    "data_set1 = pd.read_excel(os.path.join(data_path, file_name1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d53329f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13500, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acbcd7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name2 = \"(2차)34,500건.xlsx\"\n",
    "os.path.join(data_path, file_name2)\n",
    "data_set2 = pd.read_excel(os.path.join(data_path, file_name2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "268a21e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34500, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38111ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = data_set1.append(data_set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0a63ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d99ce600",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set.columns = ['uid',\n",
    "                   'publisher',\n",
    "                   'title',\n",
    "                   'summary',\n",
    "                   'content',\n",
    "                   'content_url',\n",
    "                    'update_at',\n",
    "                   'importance',\n",
    "                   'polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c46aab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>publisher</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>content</th>\n",
       "      <th>content_url</th>\n",
       "      <th>update_at</th>\n",
       "      <th>importance</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>354652739944452421</td>\n",
       "      <td>뉴스1</td>\n",
       "      <td>김진석 CJ헬로비전 대표 '주주총회 70%이상 찬성으로 합병안 가결'</td>\n",
       "      <td>임세영 기자 = 김진석 CJ헬로비전 대표가 26일 오전 서울 마포구 상암동 누리꿈스...</td>\n",
       "      <td>임세영 기자 = 김진석 CJ헬로비전 대표가 26일 오전 서울 마포구 상암동 누리꿈스...</td>\n",
       "      <td>http://news.naver.com/main/read.nhn?mode=LSD&amp;m...</td>\n",
       "      <td>2016-02-26T10:25:00</td>\n",
       "      <td>+</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  uid publisher                                   title  \\\n",
       "0  354652739944452421       뉴스1  김진석 CJ헬로비전 대표 '주주총회 70%이상 찬성으로 합병안 가결'   \n",
       "\n",
       "                                             summary  \\\n",
       "0  임세영 기자 = 김진석 CJ헬로비전 대표가 26일 오전 서울 마포구 상암동 누리꿈스...   \n",
       "\n",
       "                                             content  \\\n",
       "0  임세영 기자 = 김진석 CJ헬로비전 대표가 26일 오전 서울 마포구 상암동 누리꿈스...   \n",
       "\n",
       "                                         content_url            update_at  \\\n",
       "0  http://news.naver.com/main/read.nhn?mode=LSD&m...  2016-02-26T10:25:00   \n",
       "\n",
       "  importance polarity  \n",
       "0          +        +  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7c4953b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-    23854\n",
       "+    14656\n",
       "Name: importance, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_cleaned1 = data_set[data_set.importance.notnull()]\n",
    "# data_set_cleaned1.shape\n",
    "data_set_cleaned1_2 = data_set_cleaned1[data_set_cleaned1.polarity.notnull()]\n",
    "data_set_cleaned2 = data_set_cleaned1_2[data_set_cleaned1_2.importance != '0']\n",
    "# data_set_cleaned2.shape\n",
    "data_set_cleaned2['importance'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68dbc32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>publisher</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>content</th>\n",
       "      <th>content_url</th>\n",
       "      <th>update_at</th>\n",
       "      <th>importance</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>354652739944452421</td>\n",
       "      <td>뉴스1</td>\n",
       "      <td>김진석 CJ헬로비전 대표 '주주총회 70%이상 찬성으로 합병안 가결'</td>\n",
       "      <td>임세영 기자 = 김진석 CJ헬로비전 대표가 26일 오전 서울 마포구 상암동 누리꿈스...</td>\n",
       "      <td>임세영 기자 = 김진석 CJ헬로비전 대표가 26일 오전 서울 마포구 상암동 누리꿈스...</td>\n",
       "      <td>http://news.naver.com/main/read.nhn?mode=LSD&amp;m...</td>\n",
       "      <td>2016-02-26T10:25:00</td>\n",
       "      <td>+</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  uid publisher                                   title  \\\n",
       "0  354652739944452421       뉴스1  김진석 CJ헬로비전 대표 '주주총회 70%이상 찬성으로 합병안 가결'   \n",
       "\n",
       "                                             summary  \\\n",
       "0  임세영 기자 = 김진석 CJ헬로비전 대표가 26일 오전 서울 마포구 상암동 누리꿈스...   \n",
       "\n",
       "                                             content  \\\n",
       "0  임세영 기자 = 김진석 CJ헬로비전 대표가 26일 오전 서울 마포구 상암동 누리꿈스...   \n",
       "\n",
       "                                         content_url            update_at  \\\n",
       "0  http://news.naver.com/main/read.nhn?mode=LSD&m...  2016-02-26T10:25:00   \n",
       "\n",
       "  importance polarity  \n",
       "0          +        +  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_cleaned2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a95e34ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8207ed94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-7b66ed1a4174>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_set_cleaned2['importance_int'] = encoder.transform(data_set_cleaned2['importance'])\n",
      "<ipython-input-16-7b66ed1a4174>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_set_cleaned2['polarity_int'] = encoder.transform(data_set_cleaned2['polarity'])\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "# importance\n",
    "encoder.fit(data_set_cleaned2['importance'])\n",
    "data_set_cleaned2['importance_int'] = encoder.transform(data_set_cleaned2['importance'])\n",
    "# polarity\n",
    "encoder.fit(data_set_cleaned2['polarity'])\n",
    "data_set_cleaned2['polarity_int'] = encoder.transform(data_set_cleaned2['polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "007589c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '+', 1: '-', 2: '0'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = dict(zip(range(len(encoder.classes_)), encoder.classes_))\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51004b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-    23854\n",
       "+    14656\n",
       "Name: importance, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_cleaned2['importance'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "92e75eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-171-88e4bed54ae8>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_set_cleaned2['importance_int']=data_set_cleaned2['importance_int'].astype(np.int64)\n"
     ]
    }
   ],
   "source": [
    "data_set_cleaned2['importance_int'] = data_set_cleaned2['importance_int'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "18f50dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "7        0\n",
       "        ..\n",
       "34495    1\n",
       "34496    1\n",
       "34497    1\n",
       "34498    1\n",
       "34499    1\n",
       "Name: importance_int, Length: 38510, dtype: int64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_cleaned2['importance_int']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6612627a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    23854\n",
       "0    14656\n",
       "Name: importance_int, dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_cleaned2['importance_int'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aceb1e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25776\n",
       "+    14702\n",
       "-     6751\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_cleaned2['polarity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc7a1058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    25776\n",
       "0    14702\n",
       "1     6751\n",
       "Name: polarity_int, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_cleaned2['polarity_int'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d8e1c4",
   "metadata": {},
   "source": [
    "# 1 Binary classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a5e7da",
   "metadata": {},
   "source": [
    "### https://zzaebok.github.io/deep_learning/nlp/Bert-for-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f50e4135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pytorch-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "659429c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "bee01921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>publisher</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>content</th>\n",
       "      <th>content_url</th>\n",
       "      <th>update_at</th>\n",
       "      <th>importance</th>\n",
       "      <th>polarity</th>\n",
       "      <th>importance_int</th>\n",
       "      <th>polarity_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>354652739944452421</td>\n",
       "      <td>뉴스1</td>\n",
       "      <td>김진석 CJ헬로비전 대표 '주주총회 70%이상 찬성으로 합병안 가결'</td>\n",
       "      <td>임세영 기자 = 김진석 CJ헬로비전 대표가 26일 오전 서울 마포구 상암동 누리꿈스...</td>\n",
       "      <td>임세영 기자 = 김진석 CJ헬로비전 대표가 26일 오전 서울 마포구 상암동 누리꿈스...</td>\n",
       "      <td>http://news.naver.com/main/read.nhn?mode=LSD&amp;m...</td>\n",
       "      <td>2016-02-26T10:25:00</td>\n",
       "      <td>+</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  uid publisher                                   title  \\\n",
       "0  354652739944452421       뉴스1  김진석 CJ헬로비전 대표 '주주총회 70%이상 찬성으로 합병안 가결'   \n",
       "\n",
       "                                             summary  \\\n",
       "0  임세영 기자 = 김진석 CJ헬로비전 대표가 26일 오전 서울 마포구 상암동 누리꿈스...   \n",
       "\n",
       "                                             content  \\\n",
       "0  임세영 기자 = 김진석 CJ헬로비전 대표가 26일 오전 서울 마포구 상암동 누리꿈스...   \n",
       "\n",
       "                                         content_url            update_at  \\\n",
       "0  http://news.naver.com/main/read.nhn?mode=LSD&m...  2016-02-26T10:25:00   \n",
       "\n",
       "  importance polarity  importance_int  polarity_int  \n",
       "0          +        +               0             0  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_cleaned2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "27af9ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data_set_cleaned2[['content', 'importance_int']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "fb05e6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38510, 2)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8738f41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape is: 30808\n",
      "test shape is: 7702\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(new_data, test_size=0.2, random_state=42)\n",
    "print(\"train shape is:\", len(train))\n",
    "print(\"test shape is:\", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "42c6a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AirDataset(Dataset):\n",
    "    ''' Dataset '''\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.df.iloc[idx, 0]\n",
    "        label = self.df.iloc[idx, 1]\n",
    "        return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "54210220",
   "metadata": {},
   "outputs": [],
   "source": [
    "Air_train_dataset = AirDataset(train[:20])\n",
    "train_loader = DataLoader(Air_train_dataset,\n",
    "                         batch_size = 3,\n",
    "                         shuffle = True,\n",
    "                         num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "2b59bcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "# model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased',\n",
    "#                                                      num_labels = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d46e5e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased',\n",
    "                                                     num_labels = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05a617e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fb0ad6",
   "metadata": {},
   "source": [
    "## 1-1. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e2d2bfe5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (758 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-8f6d013fa936>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# encoding and zero padding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mencoded_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_special_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;31m# padded_list =  [e + [0] * (119547-len(e)) for e in encoded_list]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mpadded_list\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;33m[\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mencoded_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-68-8f6d013fa936>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# encoding and zero padding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mencoded_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_special_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;31m# padded_list =  [e + [0] * (119547-len(e)) for e in encoded_list]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mpadded_list\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;33m[\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mencoded_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_transformers\\tokenization_utils.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, text, text_pair, add_special_tokens, **kwargs)\u001b[0m\n\u001b[0;32m    689\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0madd_special_tokens\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 691\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_special_tokens_single_sentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    692\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_transformers\\tokenization_utils.py\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(self, text, **kwargs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[0madded_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madded_tokens_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_special_tokens\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m         \u001b[0mtokenized_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_on_tokens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madded_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    641\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_transformers\\tokenization_utils.py\u001b[0m in \u001b[0;36msplit_on_tokens\u001b[1;34m(tok_list, text)\u001b[0m\n\u001b[0;32m    628\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0msub_text\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madded_tokens_encoder\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m                             \u001b[1;32mand\u001b[0m \u001b[0msub_text\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_special_tokens\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 630\u001b[1;33m                         \u001b[0mtokenized_text\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msplit_on_token\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    631\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m                         \u001b[0mtokenized_text\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msub_text\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_transformers\\tokenization_utils.py\u001b[0m in \u001b[0;36msplit_on_token\u001b[1;34m(tok, text)\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0msplit_on_token\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 601\u001b[1;33m             \u001b[0msplit_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    602\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_text\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m                 \u001b[0msub_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msub_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(model.parameters(), lr=1e-6)\n",
    "\n",
    "itr = 500\n",
    "p_itr = 500\n",
    "epochs = 1\n",
    "total_loss = 0\n",
    "total_len = 0\n",
    "total_correct = 0\n",
    "\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for text, label in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # encoding and zero padding\n",
    "        encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
    "        # padded_list =  [e + [0] * (119547-len(e)) for e in encoded_list]\n",
    "        padded_list =  [e[:min(len(e), 512)] + [0] * (512-len(e[:min(512, len(e))])) for e in encoded_list]\n",
    "        \n",
    "        sample = torch.tensor(padded_list)\n",
    "        # sample, label = sample.to(device), label.to(device)\n",
    "        # sample, label = sample.to(device), label.to(device)\n",
    "        labels = torch.tensor(label)\n",
    "        outputs = model(sample, labels=labels)\n",
    "        loss, logits = outputs\n",
    "\n",
    "        pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "        correct = pred.eq(labels)\n",
    "        total_correct += correct.sum().item()\n",
    "        total_len += len(labels)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if itr % p_itr == 0:\n",
    "            print('[Epoch {}/{}] Iteration {} -> Train Loss: {:.4f}, Accuracy: {:.3f}'.format(epoch+1, epochs, itr, total_loss/p_itr, total_correct/total_len))\n",
    "            total_loss = 0\n",
    "            total_len = 0\n",
    "            total_correct = 0\n",
    "\n",
    "        itr+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6246f2c3",
   "metadata": {},
   "source": [
    "## 1-2. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39e2b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "model.eval()\n",
    "\n",
    "nsmc_eval_dataset = NsmcDataset(test_df)\n",
    "eval_loader = DataLoader(nsmc_eval_dataset, batch_size=2, shuffle=False, num_workers=2)\n",
    "\n",
    "total_loss = 0\n",
    "total_len = 0\n",
    "total_correct = 0\n",
    "\n",
    "for text, label in eval_loader:\n",
    "    encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
    "    padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
    "    sample = torch.tensor(padded_list)\n",
    "    sample, label = sample.to(device), label.to(device)\n",
    "    labels = torch.tensor(label)\n",
    "    outputs = model(sample, labels=labels)\n",
    "    _, logits = outputs\n",
    "\n",
    "    pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "    correct = pred.eq(labels)\n",
    "    total_correct += correct.sum().item()\n",
    "    total_len += len(labels)\n",
    "\n",
    "print('Test accuracy: ', total_correct / total_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162fd652",
   "metadata": {},
   "source": [
    "# 2 Multi class classification with BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8fa503",
   "metadata": {},
   "source": [
    "### https://towardsdatascience.com/multi-class-text-classification-with-deep-learning-using-bert-b59ca2f5c613"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "5afbd54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from transformers import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc83749",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "9d5f958d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>publisher</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>content</th>\n",
       "      <th>content_url</th>\n",
       "      <th>update_at</th>\n",
       "      <th>importance</th>\n",
       "      <th>polarity</th>\n",
       "      <th>importance_int</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>354652739944452421</td>\n",
       "      <td>뉴스1</td>\n",
       "      <td>김진석 CJ헬로비전 대표 '주주총회 70%이상 찬성으로 합병안 가결'</td>\n",
       "      <td>임세영 기자 = 김진석 CJ헬로비전 대표가 26일 오전 서울 마포구 상암동 누리꿈스...</td>\n",
       "      <td>임세영 기자 = 김진석 CJ헬로비전 대표가 26일 오전 서울 마포구 상암동 누리꿈스...</td>\n",
       "      <td>http://news.naver.com/main/read.nhn?mode=LSD&amp;m...</td>\n",
       "      <td>2016-02-26T10:25:00</td>\n",
       "      <td>+</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  uid publisher                                   title  \\\n",
       "0  354652739944452421       뉴스1  김진석 CJ헬로비전 대표 '주주총회 70%이상 찬성으로 합병안 가결'   \n",
       "\n",
       "                                             summary  \\\n",
       "0  임세영 기자 = 김진석 CJ헬로비전 대표가 26일 오전 서울 마포구 상암동 누리꿈스...   \n",
       "\n",
       "                                             content  \\\n",
       "0  임세영 기자 = 김진석 CJ헬로비전 대표가 26일 오전 서울 마포구 상암동 누리꿈스...   \n",
       "\n",
       "                                         content_url            update_at  \\\n",
       "0  http://news.naver.com/main/read.nhn?mode=LSD&m...  2016-02-26T10:25:00   \n",
       "\n",
       "  importance polarity  importance_int  label data_type  \n",
       "0          +        +               0      1     train  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_cleaned1_2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "83c46a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-    23854\n",
       "+    14656\n",
       "0     8719\n",
       "Name: importance, dtype: int64"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_cleaned1_2['importance'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "5a48f110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['+', '0', '-'], dtype=object)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_labels = data_set_cleaned1_2.importance.unique()\n",
    "possible_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c592b57",
   "metadata": {},
   "source": [
    "### Encoding the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "4ba8e763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'+': 0, '0': 1, '-': 2}"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_labels = data_set_cleaned1_2.importance.unique()\n",
    "\n",
    "label_dict ={}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index\n",
    "# label_dict['+'] = 1\n",
    "# label_dict['-'] = -1\n",
    "# label_dict['0'] = 0\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "ced8aa13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-231-2aba9da0d81b>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_set_cleaned1_2['label'] = data_set_cleaned1_2.importance.replace(label_dict)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    23854\n",
       "0    14656\n",
       "1     8719\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_cleaned1_2['label'] = data_set_cleaned1_2.importance.replace(label_dict)\n",
    "data_set_cleaned1_2['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "6a05127b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-232-f21e5db34fea>:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['data_type'] = ['not_set'] * df.shape[0]\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>publisher</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>content</th>\n",
       "      <th>content_url</th>\n",
       "      <th>update_at</th>\n",
       "      <th>polarity</th>\n",
       "      <th>importance_int</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>importance</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">+</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>11339</td>\n",
       "      <td>11339</td>\n",
       "      <td>11339</td>\n",
       "      <td>11290</td>\n",
       "      <td>11291</td>\n",
       "      <td>11339</td>\n",
       "      <td>11339</td>\n",
       "      <td>11339</td>\n",
       "      <td>11339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>3317</td>\n",
       "      <td>3317</td>\n",
       "      <td>3317</td>\n",
       "      <td>3300</td>\n",
       "      <td>3300</td>\n",
       "      <td>3317</td>\n",
       "      <td>3317</td>\n",
       "      <td>3317</td>\n",
       "      <td>3317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">-</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>18615</td>\n",
       "      <td>18615</td>\n",
       "      <td>18615</td>\n",
       "      <td>18435</td>\n",
       "      <td>18434</td>\n",
       "      <td>18615</td>\n",
       "      <td>18615</td>\n",
       "      <td>18615</td>\n",
       "      <td>18615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>5239</td>\n",
       "      <td>5239</td>\n",
       "      <td>5239</td>\n",
       "      <td>5190</td>\n",
       "      <td>5192</td>\n",
       "      <td>5239</td>\n",
       "      <td>5239</td>\n",
       "      <td>5239</td>\n",
       "      <td>5239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>6888</td>\n",
       "      <td>6888</td>\n",
       "      <td>6888</td>\n",
       "      <td>6871</td>\n",
       "      <td>6871</td>\n",
       "      <td>6888</td>\n",
       "      <td>6888</td>\n",
       "      <td>6888</td>\n",
       "      <td>6888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>1831</td>\n",
       "      <td>1831</td>\n",
       "      <td>1831</td>\n",
       "      <td>1825</td>\n",
       "      <td>1825</td>\n",
       "      <td>1831</td>\n",
       "      <td>1831</td>\n",
       "      <td>1831</td>\n",
       "      <td>1831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              uid  publisher  title  summary  content  \\\n",
       "importance label data_type                                              \n",
       "+          0     train      11339      11339  11339    11290    11291   \n",
       "                 val         3317       3317   3317     3300     3300   \n",
       "-          2     train      18615      18615  18615    18435    18434   \n",
       "                 val         5239       5239   5239     5190     5192   \n",
       "0          1     train       6888       6888   6888     6871     6871   \n",
       "                 val         1831       1831   1831     1825     1825   \n",
       "\n",
       "                            content_url  update_at  polarity  importance_int  \n",
       "importance label data_type                                                    \n",
       "+          0     train            11339      11339     11339           11339  \n",
       "                 val               3317       3317      3317            3317  \n",
       "-          2     train            18615      18615     18615           18615  \n",
       "                 val               5239       5239      5239            5239  \n",
       "0          1     train             6888       6888      6888            6888  \n",
       "                 val               1831       1831      1831            1831  "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# df = data_set_cleaned1_2['content', 'importance','label']\n",
    "df = data_set_cleaned1_2\n",
    "# df = data_set_cleaned1_2.drop(['uid',\n",
    "#                               'publisher',\n",
    "#                               'title',\n",
    "#                               'summary',\n",
    "#                               'content_url',\n",
    "#                               'update_at',\n",
    "#                               'polarity',\n",
    "#                               'importance_int'], axis = 1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(df.index.values, \n",
    "                                                  df.label.values, \n",
    "                                                  test_size = 0.15, \n",
    "                                                  random_state = 42, \n",
    "                                                  stratify = df.label.values)\n",
    "\n",
    "df['data_type'] = ['not_set'] * df.shape[0]\n",
    "\n",
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_val, 'data_type'] = 'val'\n",
    "\n",
    "df.groupby(['importance', 'label', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "78c16f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "fbda08ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2184: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type == 'train'].title.values, \n",
    "    add_special_tokens = True, \n",
    "    return_attention_mask = True, \n",
    "    pad_to_max_length = True, \n",
    "    max_length = 256, \n",
    "    return_tensors = 'pt'\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type == 'val'].title.values, \n",
    "    add_special_tokens = True, \n",
    "    return_attention_mask = True, \n",
    "    pad_to_max_length = True, \n",
    "    max_length = 256, \n",
    "    return_tensors = 'pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "866af9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(df[df.data_type == 'train'].label.values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(df[df.data_type=='val'].label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "bfe758ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "a1777658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_multiclass = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased',\n",
    "                                                                 num_labels=len(label_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9bb3ce",
   "metadata": {},
   "source": [
    "### Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "9a67b55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "batch_size = 3\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              sampler = RandomSampler(dataset_train), \n",
    "                              batch_size = batch_size)\n",
    "dataloader_validation = DataLoader(dataset_val, \n",
    "                                   sampler = SequentialSampler(dataset_val), \n",
    "                                   batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "40f8e60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=1e-5, \n",
    "                  eps=1e-8)\n",
    "                  \n",
    "epochs = 5\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90edf4d",
   "metadata": {},
   "source": [
    "### Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "3ae51b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c90aeac",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "64df646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "a94c7932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "e15da541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Administrator\\\\Desktop\\\\Work\\\\2. 인공지능리서치AIR\\\\1. source code'"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "9f7dceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "a3cb32c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92653681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ddee708702c487c8df95115be018862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ed5fe74d854323bc4c1ecea617ac17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/12281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    model_multiclass.train()\n",
    "    loss_train_total = 0\n",
    "    progress_bar = tqdm(dataloader_train, \n",
    "                        desc = 'Epoch {:1d}'.format(epoch), \n",
    "                        leave=False, \n",
    "                        disable=False)\n",
    "    for batch in progress_bar:\n",
    "        model.zero_grad()\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }       \n",
    "        outputs = model_multiclass(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "         \n",
    "   #  torch.save(model.state_dict(), 'C:\\\\Users\\\\Administrator\\\\Desktop\\\\Work\\\\2. 인공지능리서치AIR\\\\1. source code\\\\finetuned_BERT_epoch_{epoch}.model')\n",
    "        \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a75e0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
