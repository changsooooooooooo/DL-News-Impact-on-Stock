{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5fe3393",
   "metadata": {},
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7cd4b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import BertModel, DistilBertModel\n",
    "# import kobert_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dddc1c",
   "metadata": {},
   "source": [
    "# bring pre-trained kobert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0165a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_bertmodel = BertModel.from_pretrained(\"monologg/kobert\")\n",
    "# 참고\n",
    "# 아레 코드랑 결과 같음\n",
    "# model_skt = BertModel.from_pretrained(\"skt/kobert-base-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6ef7fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Administrator\\\\Desktop\\\\Work\\\\2. 인공지능리서치AIR\\\\1. source code'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5fd2fd",
   "metadata": {},
   "source": [
    "## save pre-trained kobert model (2021.07.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f93228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, 'pretrained_kobert_20210730.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d73904",
   "metadata": {},
   "source": [
    "# data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03859cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"C:/Users/Administrator/Desktop/Work/2. 인공지능리서치AIR/2. data sets/1. input data\"\n",
    "file_name1 = \"(1차)13,500건.xlsx\"\n",
    "os.path.join(data_path, file_name1)\n",
    "data_set1 = pd.read_excel(os.path.join(data_path, file_name1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d53329f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13500, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acbcd7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name2 = \"(2차)34,500건.xlsx\"\n",
    "os.path.join(data_path, file_name2)\n",
    "data_set2 = pd.read_excel(os.path.join(data_path, file_name2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "268a21e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34500, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38111ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = data_set1.append(data_set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0a63ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d99ce600",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set.columns = ['uid',\n",
    "                   'publisher',\n",
    "                   'title',\n",
    "                   'summary',\n",
    "                   'content',\n",
    "                   'content_url',\n",
    "                    'update_at',\n",
    "                   'importance',\n",
    "                   'polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c46aab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>publisher</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>content</th>\n",
       "      <th>content_url</th>\n",
       "      <th>update_at</th>\n",
       "      <th>importance</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>354652739944452421</td>\n",
       "      <td>뉴스1</td>\n",
       "      <td>김진석 CJ헬로비전 대표 '주주총회 70%이상 찬성으로 합병안 가결'</td>\n",
       "      <td>임세영 기자 = 김진석 CJ헬로비전 대표가 26일 오전 서울 마포구 상암동 누리꿈스...</td>\n",
       "      <td>임세영 기자 = 김진석 CJ헬로비전 대표가 26일 오전 서울 마포구 상암동 누리꿈스...</td>\n",
       "      <td>http://news.naver.com/main/read.nhn?mode=LSD&amp;m...</td>\n",
       "      <td>2016-02-26T10:25:00</td>\n",
       "      <td>+</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>848994285528420888</td>\n",
       "      <td>세계일보</td>\n",
       "      <td>[포토] LG유플러스 AR글라스 국내 최초 출시</td>\n",
       "      <td>LG유플러스는 21일 종각직영점에서 AR글라스를 국내 최초로 선보였다.\\n\\nAR ...</td>\n",
       "      <td>LG유플러스는 21일 종각직영점에서 AR글라스를 국내 최초로 선보였다. AR 글라스...</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LSD&amp;...</td>\n",
       "      <td>2019-11-21T13:16:00</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>384800874481980240</td>\n",
       "      <td>매일경제</td>\n",
       "      <td>LG유플러스, 전국 대리점주 200여명과 상생협력 ‘약속’</td>\n",
       "      <td>LG유플러스는 18일부터 19일 경기 광주시 곤지암리조트에 전국 대리점주를 초청해 ...</td>\n",
       "      <td>LG유플러스는 18일부터 19일 경기 광주시 곤지암리조트에 전국 대리점주를 초청해 ...</td>\n",
       "      <td>http://news.naver.com/main/read.nhn?mode=LSD&amp;m...</td>\n",
       "      <td>2016-05-19T15:02:00</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>323299472392196193</td>\n",
       "      <td>머니투데이</td>\n",
       "      <td>[사진]LG유플러스, '갤럭시 노트-S6 엣지 플러스 판매'</td>\n",
       "      <td>LG유플러스가 20일 오전 서울 중구 세종대로 시청역 직영점에서 판매를 시작한 '갤...</td>\n",
       "      <td>LG유플러스가 20일 오전 서울 중구 세종대로 시청역 직영점에서 판매를 시작한 '갤...</td>\n",
       "      <td>http://news.naver.com/main/read.nhn?mode=LSD&amp;m...</td>\n",
       "      <td>2015-08-20T12:57:00</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>809184698633949410</td>\n",
       "      <td>뉴시스</td>\n",
       "      <td>평창 발왕산 트레일 18K 안 뛰면 후회</td>\n",
       "      <td>김경목 기자 = 뉴시스 강원과 용평리조트가 주최하는 '2019 평창 발왕산 트레일 ...</td>\n",
       "      <td>김경목 기자 = 뉴시스 강원과 용평리조트가 주최하는 '2019 평창 발왕산 트레일 ...</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LSD&amp;...</td>\n",
       "      <td>2019-08-03T16:52:00</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  uid publisher                                   title  \\\n",
       "0  354652739944452421       뉴스1  김진석 CJ헬로비전 대표 '주주총회 70%이상 찬성으로 합병안 가결'   \n",
       "1  848994285528420888      세계일보              [포토] LG유플러스 AR글라스 국내 최초 출시   \n",
       "2  384800874481980240      매일경제        LG유플러스, 전국 대리점주 200여명과 상생협력 ‘약속’   \n",
       "3  323299472392196193     머니투데이       [사진]LG유플러스, '갤럭시 노트-S6 엣지 플러스 판매'   \n",
       "4  809184698633949410       뉴시스                  평창 발왕산 트레일 18K 안 뛰면 후회   \n",
       "\n",
       "                                             summary  \\\n",
       "0  임세영 기자 = 김진석 CJ헬로비전 대표가 26일 오전 서울 마포구 상암동 누리꿈스...   \n",
       "1  LG유플러스는 21일 종각직영점에서 AR글라스를 국내 최초로 선보였다.\\n\\nAR ...   \n",
       "2  LG유플러스는 18일부터 19일 경기 광주시 곤지암리조트에 전국 대리점주를 초청해 ...   \n",
       "3  LG유플러스가 20일 오전 서울 중구 세종대로 시청역 직영점에서 판매를 시작한 '갤...   \n",
       "4  김경목 기자 = 뉴시스 강원과 용평리조트가 주최하는 '2019 평창 발왕산 트레일 ...   \n",
       "\n",
       "                                             content  \\\n",
       "0  임세영 기자 = 김진석 CJ헬로비전 대표가 26일 오전 서울 마포구 상암동 누리꿈스...   \n",
       "1  LG유플러스는 21일 종각직영점에서 AR글라스를 국내 최초로 선보였다. AR 글라스...   \n",
       "2  LG유플러스는 18일부터 19일 경기 광주시 곤지암리조트에 전국 대리점주를 초청해 ...   \n",
       "3  LG유플러스가 20일 오전 서울 중구 세종대로 시청역 직영점에서 판매를 시작한 '갤...   \n",
       "4  김경목 기자 = 뉴시스 강원과 용평리조트가 주최하는 '2019 평창 발왕산 트레일 ...   \n",
       "\n",
       "                                         content_url            update_at  \\\n",
       "0  http://news.naver.com/main/read.nhn?mode=LSD&m...  2016-02-26T10:25:00   \n",
       "1  https://news.naver.com/main/read.nhn?mode=LSD&...  2019-11-21T13:16:00   \n",
       "2  http://news.naver.com/main/read.nhn?mode=LSD&m...  2016-05-19T15:02:00   \n",
       "3  http://news.naver.com/main/read.nhn?mode=LSD&m...  2015-08-20T12:57:00   \n",
       "4  https://news.naver.com/main/read.nhn?mode=LSD&...  2019-08-03T16:52:00   \n",
       "\n",
       "  importance polarity  \n",
       "0          +        +  \n",
       "1          0        +  \n",
       "2          -        0  \n",
       "3          -        0  \n",
       "4          -        0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7c4953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_cleaned1 = data_set[data_set.importance.notnull()]\n",
    "# data_set_cleaned1.shape\n",
    "data_set_cleaned2 = data_set_cleaned1[data_set_cleaned1.polarity.notnull()]\n",
    "# data_set_cleaned2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8587de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68dbc32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>publisher</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>content</th>\n",
       "      <th>content_url</th>\n",
       "      <th>update_at</th>\n",
       "      <th>importance</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>354652739944452421</td>\n",
       "      <td>뉴스1</td>\n",
       "      <td>김진석 CJ헬로비전 대표 '주주총회 70%이상 찬성으로 합병안 가결'</td>\n",
       "      <td>임세영 기자 = 김진석 CJ헬로비전 대표가 26일 오전 서울 마포구 상암동 누리꿈스...</td>\n",
       "      <td>임세영 기자 = 김진석 CJ헬로비전 대표가 26일 오전 서울 마포구 상암동 누리꿈스...</td>\n",
       "      <td>http://news.naver.com/main/read.nhn?mode=LSD&amp;m...</td>\n",
       "      <td>2016-02-26T10:25:00</td>\n",
       "      <td>+</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>848994285528420888</td>\n",
       "      <td>세계일보</td>\n",
       "      <td>[포토] LG유플러스 AR글라스 국내 최초 출시</td>\n",
       "      <td>LG유플러스는 21일 종각직영점에서 AR글라스를 국내 최초로 선보였다.\\n\\nAR ...</td>\n",
       "      <td>LG유플러스는 21일 종각직영점에서 AR글라스를 국내 최초로 선보였다. AR 글라스...</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LSD&amp;...</td>\n",
       "      <td>2019-11-21T13:16:00</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>384800874481980240</td>\n",
       "      <td>매일경제</td>\n",
       "      <td>LG유플러스, 전국 대리점주 200여명과 상생협력 ‘약속’</td>\n",
       "      <td>LG유플러스는 18일부터 19일 경기 광주시 곤지암리조트에 전국 대리점주를 초청해 ...</td>\n",
       "      <td>LG유플러스는 18일부터 19일 경기 광주시 곤지암리조트에 전국 대리점주를 초청해 ...</td>\n",
       "      <td>http://news.naver.com/main/read.nhn?mode=LSD&amp;m...</td>\n",
       "      <td>2016-05-19T15:02:00</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>323299472392196193</td>\n",
       "      <td>머니투데이</td>\n",
       "      <td>[사진]LG유플러스, '갤럭시 노트-S6 엣지 플러스 판매'</td>\n",
       "      <td>LG유플러스가 20일 오전 서울 중구 세종대로 시청역 직영점에서 판매를 시작한 '갤...</td>\n",
       "      <td>LG유플러스가 20일 오전 서울 중구 세종대로 시청역 직영점에서 판매를 시작한 '갤...</td>\n",
       "      <td>http://news.naver.com/main/read.nhn?mode=LSD&amp;m...</td>\n",
       "      <td>2015-08-20T12:57:00</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>809184698633949410</td>\n",
       "      <td>뉴시스</td>\n",
       "      <td>평창 발왕산 트레일 18K 안 뛰면 후회</td>\n",
       "      <td>김경목 기자 = 뉴시스 강원과 용평리조트가 주최하는 '2019 평창 발왕산 트레일 ...</td>\n",
       "      <td>김경목 기자 = 뉴시스 강원과 용평리조트가 주최하는 '2019 평창 발왕산 트레일 ...</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LSD&amp;...</td>\n",
       "      <td>2019-08-03T16:52:00</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  uid publisher                                   title  \\\n",
       "0  354652739944452421       뉴스1  김진석 CJ헬로비전 대표 '주주총회 70%이상 찬성으로 합병안 가결'   \n",
       "1  848994285528420888      세계일보              [포토] LG유플러스 AR글라스 국내 최초 출시   \n",
       "2  384800874481980240      매일경제        LG유플러스, 전국 대리점주 200여명과 상생협력 ‘약속’   \n",
       "3  323299472392196193     머니투데이       [사진]LG유플러스, '갤럭시 노트-S6 엣지 플러스 판매'   \n",
       "4  809184698633949410       뉴시스                  평창 발왕산 트레일 18K 안 뛰면 후회   \n",
       "\n",
       "                                             summary  \\\n",
       "0  임세영 기자 = 김진석 CJ헬로비전 대표가 26일 오전 서울 마포구 상암동 누리꿈스...   \n",
       "1  LG유플러스는 21일 종각직영점에서 AR글라스를 국내 최초로 선보였다.\\n\\nAR ...   \n",
       "2  LG유플러스는 18일부터 19일 경기 광주시 곤지암리조트에 전국 대리점주를 초청해 ...   \n",
       "3  LG유플러스가 20일 오전 서울 중구 세종대로 시청역 직영점에서 판매를 시작한 '갤...   \n",
       "4  김경목 기자 = 뉴시스 강원과 용평리조트가 주최하는 '2019 평창 발왕산 트레일 ...   \n",
       "\n",
       "                                             content  \\\n",
       "0  임세영 기자 = 김진석 CJ헬로비전 대표가 26일 오전 서울 마포구 상암동 누리꿈스...   \n",
       "1  LG유플러스는 21일 종각직영점에서 AR글라스를 국내 최초로 선보였다. AR 글라스...   \n",
       "2  LG유플러스는 18일부터 19일 경기 광주시 곤지암리조트에 전국 대리점주를 초청해 ...   \n",
       "3  LG유플러스가 20일 오전 서울 중구 세종대로 시청역 직영점에서 판매를 시작한 '갤...   \n",
       "4  김경목 기자 = 뉴시스 강원과 용평리조트가 주최하는 '2019 평창 발왕산 트레일 ...   \n",
       "\n",
       "                                         content_url            update_at  \\\n",
       "0  http://news.naver.com/main/read.nhn?mode=LSD&m...  2016-02-26T10:25:00   \n",
       "1  https://news.naver.com/main/read.nhn?mode=LSD&...  2019-11-21T13:16:00   \n",
       "2  http://news.naver.com/main/read.nhn?mode=LSD&m...  2016-05-19T15:02:00   \n",
       "3  http://news.naver.com/main/read.nhn?mode=LSD&m...  2015-08-20T12:57:00   \n",
       "4  https://news.naver.com/main/read.nhn?mode=LSD&...  2019-08-03T16:52:00   \n",
       "\n",
       "  importance polarity  \n",
       "0          +        +  \n",
       "1          0        +  \n",
       "2          -        0  \n",
       "3          -        0  \n",
       "4          -        0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_cleaned2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a95e34ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8207ed94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7b66ed1a4174>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_set_cleaned2['importance_int'] = encoder.transform(data_set_cleaned2['importance'])\n",
      "<ipython-input-27-7b66ed1a4174>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_set_cleaned2['polarity_int'] = encoder.transform(data_set_cleaned2['polarity'])\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "# importance\n",
    "encoder.fit(data_set_cleaned2['importance'])\n",
    "data_set_cleaned2['importance_int'] = encoder.transform(data_set_cleaned2['importance'])\n",
    "# polarity\n",
    "encoder.fit(data_set_cleaned2['polarity'])\n",
    "data_set_cleaned2['polarity_int'] = encoder.transform(data_set_cleaned2['polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34f382ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>publisher</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>content</th>\n",
       "      <th>content_url</th>\n",
       "      <th>update_at</th>\n",
       "      <th>importance</th>\n",
       "      <th>polarity</th>\n",
       "      <th>importance_int</th>\n",
       "      <th>polarity_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>354652739944452421</td>\n",
       "      <td>뉴스1</td>\n",
       "      <td>김진석 CJ헬로비전 대표 '주주총회 70%이상 찬성으로 합병안 가결'</td>\n",
       "      <td>임세영 기자 = 김진석 CJ헬로비전 대표가 26일 오전 서울 마포구 상암동 누리꿈스...</td>\n",
       "      <td>임세영 기자 = 김진석 CJ헬로비전 대표가 26일 오전 서울 마포구 상암동 누리꿈스...</td>\n",
       "      <td>http://news.naver.com/main/read.nhn?mode=LSD&amp;m...</td>\n",
       "      <td>2016-02-26T10:25:00</td>\n",
       "      <td>+</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>848994285528420888</td>\n",
       "      <td>세계일보</td>\n",
       "      <td>[포토] LG유플러스 AR글라스 국내 최초 출시</td>\n",
       "      <td>LG유플러스는 21일 종각직영점에서 AR글라스를 국내 최초로 선보였다.\\n\\nAR ...</td>\n",
       "      <td>LG유플러스는 21일 종각직영점에서 AR글라스를 국내 최초로 선보였다. AR 글라스...</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LSD&amp;...</td>\n",
       "      <td>2019-11-21T13:16:00</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>384800874481980240</td>\n",
       "      <td>매일경제</td>\n",
       "      <td>LG유플러스, 전국 대리점주 200여명과 상생협력 ‘약속’</td>\n",
       "      <td>LG유플러스는 18일부터 19일 경기 광주시 곤지암리조트에 전국 대리점주를 초청해 ...</td>\n",
       "      <td>LG유플러스는 18일부터 19일 경기 광주시 곤지암리조트에 전국 대리점주를 초청해 ...</td>\n",
       "      <td>http://news.naver.com/main/read.nhn?mode=LSD&amp;m...</td>\n",
       "      <td>2016-05-19T15:02:00</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>323299472392196193</td>\n",
       "      <td>머니투데이</td>\n",
       "      <td>[사진]LG유플러스, '갤럭시 노트-S6 엣지 플러스 판매'</td>\n",
       "      <td>LG유플러스가 20일 오전 서울 중구 세종대로 시청역 직영점에서 판매를 시작한 '갤...</td>\n",
       "      <td>LG유플러스가 20일 오전 서울 중구 세종대로 시청역 직영점에서 판매를 시작한 '갤...</td>\n",
       "      <td>http://news.naver.com/main/read.nhn?mode=LSD&amp;m...</td>\n",
       "      <td>2015-08-20T12:57:00</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>809184698633949410</td>\n",
       "      <td>뉴시스</td>\n",
       "      <td>평창 발왕산 트레일 18K 안 뛰면 후회</td>\n",
       "      <td>김경목 기자 = 뉴시스 강원과 용평리조트가 주최하는 '2019 평창 발왕산 트레일 ...</td>\n",
       "      <td>김경목 기자 = 뉴시스 강원과 용평리조트가 주최하는 '2019 평창 발왕산 트레일 ...</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LSD&amp;...</td>\n",
       "      <td>2019-08-03T16:52:00</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  uid publisher                                   title  \\\n",
       "0  354652739944452421       뉴스1  김진석 CJ헬로비전 대표 '주주총회 70%이상 찬성으로 합병안 가결'   \n",
       "1  848994285528420888      세계일보              [포토] LG유플러스 AR글라스 국내 최초 출시   \n",
       "2  384800874481980240      매일경제        LG유플러스, 전국 대리점주 200여명과 상생협력 ‘약속’   \n",
       "3  323299472392196193     머니투데이       [사진]LG유플러스, '갤럭시 노트-S6 엣지 플러스 판매'   \n",
       "4  809184698633949410       뉴시스                  평창 발왕산 트레일 18K 안 뛰면 후회   \n",
       "\n",
       "                                             summary  \\\n",
       "0  임세영 기자 = 김진석 CJ헬로비전 대표가 26일 오전 서울 마포구 상암동 누리꿈스...   \n",
       "1  LG유플러스는 21일 종각직영점에서 AR글라스를 국내 최초로 선보였다.\\n\\nAR ...   \n",
       "2  LG유플러스는 18일부터 19일 경기 광주시 곤지암리조트에 전국 대리점주를 초청해 ...   \n",
       "3  LG유플러스가 20일 오전 서울 중구 세종대로 시청역 직영점에서 판매를 시작한 '갤...   \n",
       "4  김경목 기자 = 뉴시스 강원과 용평리조트가 주최하는 '2019 평창 발왕산 트레일 ...   \n",
       "\n",
       "                                             content  \\\n",
       "0  임세영 기자 = 김진석 CJ헬로비전 대표가 26일 오전 서울 마포구 상암동 누리꿈스...   \n",
       "1  LG유플러스는 21일 종각직영점에서 AR글라스를 국내 최초로 선보였다. AR 글라스...   \n",
       "2  LG유플러스는 18일부터 19일 경기 광주시 곤지암리조트에 전국 대리점주를 초청해 ...   \n",
       "3  LG유플러스가 20일 오전 서울 중구 세종대로 시청역 직영점에서 판매를 시작한 '갤...   \n",
       "4  김경목 기자 = 뉴시스 강원과 용평리조트가 주최하는 '2019 평창 발왕산 트레일 ...   \n",
       "\n",
       "                                         content_url            update_at  \\\n",
       "0  http://news.naver.com/main/read.nhn?mode=LSD&m...  2016-02-26T10:25:00   \n",
       "1  https://news.naver.com/main/read.nhn?mode=LSD&...  2019-11-21T13:16:00   \n",
       "2  http://news.naver.com/main/read.nhn?mode=LSD&m...  2016-05-19T15:02:00   \n",
       "3  http://news.naver.com/main/read.nhn?mode=LSD&m...  2015-08-20T12:57:00   \n",
       "4  https://news.naver.com/main/read.nhn?mode=LSD&...  2019-08-03T16:52:00   \n",
       "\n",
       "  importance polarity  importance_int  polarity_int  \n",
       "0          +        +               0             0  \n",
       "1          0        +               2             0  \n",
       "2          -        0               1             2  \n",
       "3          -        0               1             2  \n",
       "4          -        0               1             2  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_cleaned2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "007589c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '+', 1: '-', 2: '0'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = dict(zip(range(len(encoder.classes_)), encoder.classes_))\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4583e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(new_data, test_size=0.2, random_state=42)\n",
    "print(\"train shape is:\", len(train))\n",
    "print(\"test shape is:\", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51004b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-    23854\n",
       "+    14656\n",
       "0     8719\n",
       "Name: importance, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_cleaned2['importance'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6612627a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    23854\n",
       "0    14656\n",
       "2     8719\n",
       "Name: importance_int, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_cleaned2['importance_int'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aceb1e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25776\n",
       "+    14702\n",
       "-     6751\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_cleaned2['polarity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc7a1058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    25776\n",
       "0    14702\n",
       "1     6751\n",
       "Name: polarity_int, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_cleaned2['polarity_int'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169dc0e5",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73fdb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "kobert_transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "22e434f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'KoBertTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "from kobert_transformers import get_tokenizer\n",
    "tokenizer = get_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d11fb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', '▁한국', '어', '▁모델', '을', '▁공유', '합니다', '.', '[SEP]']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"[CLS] 한국어 모델을 공유합니다. [SEP]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "420eec25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4958, 6855, 2046, 7088, 1050, 7843, 54, 3]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(['[CLS]', '▁한국', '어', '▁모델', '을', '▁공유', '합니다', '.', '[SEP]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1603c209",
   "metadata": {},
   "source": [
    "## example - AIR data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6b29d41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁김진',\n",
       " '석',\n",
       " '▁CJ',\n",
       " '헬',\n",
       " '로',\n",
       " '비',\n",
       " '전',\n",
       " '▁대표',\n",
       " \"▁'\",\n",
       " '주',\n",
       " '주',\n",
       " '총회',\n",
       " '▁70%',\n",
       " '이상',\n",
       " '▁찬성',\n",
       " '으로',\n",
       " '▁합병',\n",
       " '안',\n",
       " '▁',\n",
       " '가',\n",
       " '결',\n",
       " \"'\"]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(data_set.iloc[0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d649ba8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁임',\n",
       " '세',\n",
       " '영',\n",
       " '▁',\n",
       " '기자',\n",
       " '▁=',\n",
       " '▁김진',\n",
       " '석',\n",
       " '▁CJ',\n",
       " '헬',\n",
       " '로',\n",
       " '비',\n",
       " '전',\n",
       " '▁대표',\n",
       " '가',\n",
       " '▁26',\n",
       " '일',\n",
       " '▁오전',\n",
       " '▁서울',\n",
       " '▁마',\n",
       " '포',\n",
       " '구',\n",
       " '▁상',\n",
       " '암',\n",
       " '동',\n",
       " '▁누',\n",
       " '리',\n",
       " '꿈',\n",
       " '스',\n",
       " '퀘',\n",
       " '어',\n",
       " '에서',\n",
       " '▁열린',\n",
       " \"▁'\",\n",
       " 'C',\n",
       " 'J',\n",
       " '헬',\n",
       " '로',\n",
       " '비',\n",
       " '전',\n",
       " '▁임시',\n",
       " '주',\n",
       " '주',\n",
       " '총회',\n",
       " \"'\",\n",
       " '를',\n",
       " '▁마치고',\n",
       " '▁취재진',\n",
       " '의',\n",
       " '▁질문에',\n",
       " '▁답',\n",
       " '하고',\n",
       " '▁있다',\n",
       " '.',\n",
       " '▁이날',\n",
       " '▁김진',\n",
       " '석',\n",
       " '▁CJ',\n",
       " '헬',\n",
       " '로',\n",
       " '비',\n",
       " '전',\n",
       " '▁대표는',\n",
       " '▁“',\n",
       " '이번',\n",
       " '▁주주',\n",
       " '총회',\n",
       " '에서',\n",
       " '▁전체',\n",
       " '▁70%',\n",
       " '▁이상',\n",
       " '▁찬성',\n",
       " '으로',\n",
       " '▁SK',\n",
       " '브',\n",
       " '로',\n",
       " '드',\n",
       " '밴드',\n",
       " '▁합병',\n",
       " '안',\n",
       " '건',\n",
       " '이',\n",
       " '▁',\n",
       " '가',\n",
       " '결',\n",
       " '됐다',\n",
       " '”',\n",
       " '고',\n",
       " '▁밝혔다',\n",
       " '.']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(data_set.iloc[0, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd04cd6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9ff0665",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b06585b4",
   "metadata": {},
   "source": [
    "# Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd45bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214273c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf737a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71b4c389",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f794fe",
   "metadata": {},
   "source": [
    "###  https://github.com/aeddung/ML-DL/blob/main/NLP/koBert_multiclassification.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6e564b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df134a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kobert.utils import get_tokenizer\n",
    "# from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa21d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence_output, pooled_output = model(input_ids, attention_mask, token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4b6b65ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair) \n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ffa8f6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a1abe6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'KoBertTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "# 기본 Bert tokenizer 사용\n",
    "from kobert_transformers import get_tokenizer\n",
    "tokenizer = get_tokenizer()\n",
    "# tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c3be539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters\n",
    "max_len = 64 # 해당 길이를 초과하는 단어에 대해선 bert가 학습하지 않음\n",
    "batch_size = 64\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 5\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78afd03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train = BERTDataset(train, 0, 1, tok, max_len, True, False)\n",
    "#data_test = BERTDataset(test, 0, 1, tok, max_len, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "55cbe6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data_set_cleaned2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eae26c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape is: 37783\n",
      "test shape is: 9446\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(new_data, test_size=0.2, random_state=42)\n",
    "print(\"train shape is:\", len(train))\n",
    "print(\"test shape is:\", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "50844d06",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-6bcde21e3de2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBERTDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBERTDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-47-6990c9df79e8>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len, pad, pair)\u001b[0m\n\u001b[0;32m      2\u001b[0m     def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n\u001b[0;32m      3\u001b[0m                  pad, pair):\n\u001b[1;32m----> 4\u001b[1;33m         transform = nlp.data.BERTSentenceTransform(\n\u001b[0m\u001b[0;32m      5\u001b[0m             bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair) \n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "data_train = BERTDataset(train, 0, 1, tokenizer, max_len, True, False)\n",
    "data_test = BERTDataset(test, 0, 1, tokenizer, max_len, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8b46dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes = 3, # softmax 사용 <- binary일 경우는 2\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "63a0fd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTClassifier(pretrained_bertmodel, dr_rate=0.5) #.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "37a66306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "# 옵티마이저 선언\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss() # softmax용 Loss Function 정하기 <- binary classification도 해당 loss function 사용 가능\n",
    "\n",
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f001b6e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-6bcde21e3de2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBERTDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBERTDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-47-6990c9df79e8>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len, pad, pair)\u001b[0m\n\u001b[0;32m      2\u001b[0m     def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n\u001b[0;32m      3\u001b[0m                  pad, pair):\n\u001b[1;32m----> 4\u001b[1;33m         transform = nlp.data.BERTSentenceTransform(\n\u001b[0m\u001b[0;32m      5\u001b[0m             bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair) \n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "data_train = BERTDataset(train, 0, 1, tokenizer, max_len, True, False)\n",
    "data_test = BERTDataset(test, 0, 1, tokenizer, max_len, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "47d76560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train = \n",
    "#data_test = \n",
    "# pytorch용 DataLoader 사용\n",
    "train_dataloader = torch.utils.data.DataLoader(train, batch_size = batch_size, num_workers=5)\n",
    "test_dataloader = torch.utils.data.DataLoader(test, batch_size = batch_size, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6265ae65",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(token_ids, valid_length, segment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "217e78c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f371f24",
   "metadata": {},
   "source": [
    "## Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a59b4a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-84-1e1dbabbe0cf>:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm.tqdm_notebook(train_dataloader)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e251b31efff4afd8a1385633fc5681e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/591 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3080, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas\\_libs\\index.pyx\", line 70, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\index.pyx\", line 101, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 4554, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 4562, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 0\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 3024, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3082, in get_loc\n    raise KeyError(key) from err\nKeyError: 0\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-1e1dbabbe0cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#         optimizer.zero_grad()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tqdm\\notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    246\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m                 \u001b[1;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1201\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m                 \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1203\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1227\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1228\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1229\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1230\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    423\u001b[0m             \u001b[1;31m# have message field\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3080, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas\\_libs\\index.pyx\", line 70, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\index.pyx\", line 101, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 4554, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 4562, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 0\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 3024, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3082, in get_loc\n    raise KeyError(key) from err\nKeyError: 0\n"
     ]
    }
   ],
   "source": [
    "for e in range(num_epochs):\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    model.train()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm.tqdm_notebook(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long() #.to(device)\n",
    "        segment_ids = segment_ids.long() #.to(device)\n",
    "        valid_length = valid_length\n",
    "        label = label.long() #.to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm) # gradient clipping\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        train_acc += calc_accuracy(out, label)\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7062180b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28f16a71",
   "metadata": {},
   "source": [
    "# Classifier2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116b26a0",
   "metadata": {},
   "source": [
    "### https://tech-diary.tistory.com/31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ba938869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters\n",
    "max_len = 64 # 해당 길이를 초과하는 단어에 대해선 bert가 학습하지 않음\n",
    "batch_size = 64\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 5\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9fd1bba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_bertmodel = BertModel.from_pretrained(\"monologg/kobert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3cf65db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes = 3, # softmax 사용 <- binary일 경우는 2\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "75fc9122",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTClassifier(pretrained_bertmodel, dr_rate=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266cddae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37d8e1c4",
   "metadata": {},
   "source": [
    "# Classifier 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a5e7da",
   "metadata": {},
   "source": [
    "### https://zzaebok.github.io/deep_learning/nlp/Bert-for-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f50e4135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pytorch-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "659429c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bee01921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>publisher</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>content</th>\n",
       "      <th>content_url</th>\n",
       "      <th>update_at</th>\n",
       "      <th>importance</th>\n",
       "      <th>polarity</th>\n",
       "      <th>importance_int</th>\n",
       "      <th>polarity_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>354652739944452421</td>\n",
       "      <td>뉴스1</td>\n",
       "      <td>김진석 CJ헬로비전 대표 '주주총회 70%이상 찬성으로 합병안 가결'</td>\n",
       "      <td>임세영 기자 = 김진석 CJ헬로비전 대표가 26일 오전 서울 마포구 상암동 누리꿈스...</td>\n",
       "      <td>임세영 기자 = 김진석 CJ헬로비전 대표가 26일 오전 서울 마포구 상암동 누리꿈스...</td>\n",
       "      <td>http://news.naver.com/main/read.nhn?mode=LSD&amp;m...</td>\n",
       "      <td>2016-02-26T10:25:00</td>\n",
       "      <td>+</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>848994285528420888</td>\n",
       "      <td>세계일보</td>\n",
       "      <td>[포토] LG유플러스 AR글라스 국내 최초 출시</td>\n",
       "      <td>LG유플러스는 21일 종각직영점에서 AR글라스를 국내 최초로 선보였다.\\n\\nAR ...</td>\n",
       "      <td>LG유플러스는 21일 종각직영점에서 AR글라스를 국내 최초로 선보였다. AR 글라스...</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LSD&amp;...</td>\n",
       "      <td>2019-11-21T13:16:00</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>384800874481980240</td>\n",
       "      <td>매일경제</td>\n",
       "      <td>LG유플러스, 전국 대리점주 200여명과 상생협력 ‘약속’</td>\n",
       "      <td>LG유플러스는 18일부터 19일 경기 광주시 곤지암리조트에 전국 대리점주를 초청해 ...</td>\n",
       "      <td>LG유플러스는 18일부터 19일 경기 광주시 곤지암리조트에 전국 대리점주를 초청해 ...</td>\n",
       "      <td>http://news.naver.com/main/read.nhn?mode=LSD&amp;m...</td>\n",
       "      <td>2016-05-19T15:02:00</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>323299472392196193</td>\n",
       "      <td>머니투데이</td>\n",
       "      <td>[사진]LG유플러스, '갤럭시 노트-S6 엣지 플러스 판매'</td>\n",
       "      <td>LG유플러스가 20일 오전 서울 중구 세종대로 시청역 직영점에서 판매를 시작한 '갤...</td>\n",
       "      <td>LG유플러스가 20일 오전 서울 중구 세종대로 시청역 직영점에서 판매를 시작한 '갤...</td>\n",
       "      <td>http://news.naver.com/main/read.nhn?mode=LSD&amp;m...</td>\n",
       "      <td>2015-08-20T12:57:00</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>809184698633949410</td>\n",
       "      <td>뉴시스</td>\n",
       "      <td>평창 발왕산 트레일 18K 안 뛰면 후회</td>\n",
       "      <td>김경목 기자 = 뉴시스 강원과 용평리조트가 주최하는 '2019 평창 발왕산 트레일 ...</td>\n",
       "      <td>김경목 기자 = 뉴시스 강원과 용평리조트가 주최하는 '2019 평창 발왕산 트레일 ...</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LSD&amp;...</td>\n",
       "      <td>2019-08-03T16:52:00</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  uid publisher                                   title  \\\n",
       "0  354652739944452421       뉴스1  김진석 CJ헬로비전 대표 '주주총회 70%이상 찬성으로 합병안 가결'   \n",
       "1  848994285528420888      세계일보              [포토] LG유플러스 AR글라스 국내 최초 출시   \n",
       "2  384800874481980240      매일경제        LG유플러스, 전국 대리점주 200여명과 상생협력 ‘약속’   \n",
       "3  323299472392196193     머니투데이       [사진]LG유플러스, '갤럭시 노트-S6 엣지 플러스 판매'   \n",
       "4  809184698633949410       뉴시스                  평창 발왕산 트레일 18K 안 뛰면 후회   \n",
       "\n",
       "                                             summary  \\\n",
       "0  임세영 기자 = 김진석 CJ헬로비전 대표가 26일 오전 서울 마포구 상암동 누리꿈스...   \n",
       "1  LG유플러스는 21일 종각직영점에서 AR글라스를 국내 최초로 선보였다.\\n\\nAR ...   \n",
       "2  LG유플러스는 18일부터 19일 경기 광주시 곤지암리조트에 전국 대리점주를 초청해 ...   \n",
       "3  LG유플러스가 20일 오전 서울 중구 세종대로 시청역 직영점에서 판매를 시작한 '갤...   \n",
       "4  김경목 기자 = 뉴시스 강원과 용평리조트가 주최하는 '2019 평창 발왕산 트레일 ...   \n",
       "\n",
       "                                             content  \\\n",
       "0  임세영 기자 = 김진석 CJ헬로비전 대표가 26일 오전 서울 마포구 상암동 누리꿈스...   \n",
       "1  LG유플러스는 21일 종각직영점에서 AR글라스를 국내 최초로 선보였다. AR 글라스...   \n",
       "2  LG유플러스는 18일부터 19일 경기 광주시 곤지암리조트에 전국 대리점주를 초청해 ...   \n",
       "3  LG유플러스가 20일 오전 서울 중구 세종대로 시청역 직영점에서 판매를 시작한 '갤...   \n",
       "4  김경목 기자 = 뉴시스 강원과 용평리조트가 주최하는 '2019 평창 발왕산 트레일 ...   \n",
       "\n",
       "                                         content_url            update_at  \\\n",
       "0  http://news.naver.com/main/read.nhn?mode=LSD&m...  2016-02-26T10:25:00   \n",
       "1  https://news.naver.com/main/read.nhn?mode=LSD&...  2019-11-21T13:16:00   \n",
       "2  http://news.naver.com/main/read.nhn?mode=LSD&m...  2016-05-19T15:02:00   \n",
       "3  http://news.naver.com/main/read.nhn?mode=LSD&m...  2015-08-20T12:57:00   \n",
       "4  https://news.naver.com/main/read.nhn?mode=LSD&...  2019-08-03T16:52:00   \n",
       "\n",
       "  importance polarity  importance_int  polarity_int  \n",
       "0          +        +               0             0  \n",
       "1          0        +               2             0  \n",
       "2          -        0               1             2  \n",
       "3          -        0               1             2  \n",
       "4          -        0               1             2  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_cleaned2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "27af9ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data_set_cleaned2[['content', 'importance_int']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8738f41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape is: 37783\n",
      "test shape is: 9446\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(new_data, test_size=0.2, random_state=42)\n",
    "print(\"train shape is:\", len(train))\n",
    "print(\"test shape is:\", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc8b740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "42c6a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AirDataset(Dataset):\n",
    "    ''' Dataset '''\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.df.iloc[idx, 1]\n",
    "        label = self.df.iloc[idx, 2]\n",
    "        return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "54210220",
   "metadata": {},
   "outputs": [],
   "source": [
    "Air_train_dataset = AirDataset(train)\n",
    "train_loader = DataLoader(Air_train_dataset,\n",
    "                         batch_size = 10,\n",
    "                         shuffle = True,\n",
    "                         num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9d1af1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2b59bcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 995526/995526 [00:01<00:00, 572890.57B/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 625/625 [00:00<00:00, 15595.92B/s]\n",
      "100%|████████████████████████████████████████████████████████████████| 714314041/714314041 [10:18<00:00, 1155719.34B/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "65bdd85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d2bfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=1e-6)\n",
    "\n",
    "itr = 1\n",
    "p_itr = 500\n",
    "epochs = 1\n",
    "total_loss = 0\n",
    "total_len = 0\n",
    "total_correct = 0\n",
    "\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for text, label in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # encoding and zero padding\n",
    "        encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
    "        padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
    "        \n",
    "        sample = torch.tensor(padded_list)\n",
    "        # sample, label = sample.to(device), label.to(device)\n",
    "        # sample, label = sample.to(device), label.to(device)\n",
    "        labels = torch.tensor(label)\n",
    "        outputs = model(sample, labels=labels)\n",
    "        loss, logits = outputs\n",
    "\n",
    "        pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "        correct = pred.eq(labels)\n",
    "        total_correct += correct.sum().item()\n",
    "        total_len += len(labels)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if itr % p_itr == 0:\n",
    "            print('[Epoch {}/{}] Iteration {} -> Train Loss: {:.4f}, Accuracy: {:.3f}'.format(epoch+1, epochs, itr, total_loss/p_itr, total_correct/total_len))\n",
    "            total_loss = 0\n",
    "            total_len = 0\n",
    "            total_correct = 0\n",
    "\n",
    "        itr+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39e2b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "model.eval()\n",
    "\n",
    "nsmc_eval_dataset = NsmcDataset(test_df)\n",
    "eval_loader = DataLoader(nsmc_eval_dataset, batch_size=2, shuffle=False, num_workers=2)\n",
    "\n",
    "total_loss = 0\n",
    "total_len = 0\n",
    "total_correct = 0\n",
    "\n",
    "for text, label in eval_loader:\n",
    "    encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
    "    padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
    "    sample = torch.tensor(padded_list)\n",
    "    sample, label = sample.to(device), label.to(device)\n",
    "    labels = torch.tensor(label)\n",
    "    outputs = model(sample, labels=labels)\n",
    "    _, logits = outputs\n",
    "\n",
    "    pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "    correct = pred.eq(labels)\n",
    "    total_correct += correct.sum().item()\n",
    "    total_len += len(labels)\n",
    "\n",
    "print('Test accuracy: ', total_correct / total_len)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
