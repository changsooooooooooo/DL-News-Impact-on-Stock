{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "503e6d5b-60bc-4dd5-bbc2-49264d3337f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from transformers import BertModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from kobert_tokenizer import KoBERTTokenizer\n",
    "from adamp import AdamP\n",
    "import torch.nn as nn\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753799f2-b816-4184-8c62-cec9ebe19e4f",
   "metadata": {},
   "source": [
    "### Tokenizing Additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02300524-8ce7-4c73-a557-356ac4db1210",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 10\n",
    "max_len = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d8d749b-8bf2-4835-afa6-7fa1ae282300",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenMaking():\n",
    "  def __init__(self, data):\n",
    "    self.data = data\n",
    "\n",
    "  def attention_mask(self):\n",
    "    return np.random.choice(2, size=( len(self.data), ), p = [0.8, 0.2]).tolist()\n",
    "    \n",
    "  def token_type_id(self):\n",
    "    return [0 for _ in range(max_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52fa619d-20d3-47e5-9c76-838cfd762c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ids(tokenizer, string_):\n",
    "  tokenized_string = tokenizer.tokenize(string_)\n",
    "  return tokenizer.convert_tokens_to_ids(tokenized_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03fab096-8086-411e-b54e-bd6ed51f6924",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fae7252-97e9-4a19-bc0f-8a6052e28528",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [pd.read_excel(file, engine='openpyxl') for file in os.listdir() if file.endswith(\"xlsx\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa3d9e63-64e7-4555-b3f4-7e98b0c0f314",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].dropna(subset=[\"content\", \"summary\", \"중요도(+/0/-)\", \"극성값(+/0/-)\"], inplace = True)\n",
    "data[1].dropna(subset=[\"content\", \"summary\", \"중요도(+/0/-)\", \"극성값(+/0/-)\"], inplace = True)\n",
    "for i in range(2):\n",
    "  data[i].loc[:, \"content\"].replace('[-=+,#/\\?:^$@*\\\"※~&%ㆍ!』\\\\‘|\\[\\]\\<\\>`\\'…》]', \" \", regex=True, inplace=True)\n",
    "  data[i].loc[:, \"content\"].replace('\\n', \"\", regex=True, inplace=True)\n",
    "  data[i].loc[:, \"summary\"].replace('[-=+,#/\\?:^$@*\\\"※~&%ㆍ!』\\\\‘|\\[\\]\\<\\>`\\'…》]', \" \", regex=True, inplace=True)\n",
    "  data[i].loc[:, \"summary\"].replace('\\n', \"\", regex=True, inplace=True)\n",
    "  data[i].loc[:, \"content\"].replace('[가-힣]+ 기자', \"\", regex=True, inplace=True)\n",
    "  data[i].loc[:, \"summary\"].replace('[가-힣]+ 기자', \"\", regex=True, inplace=True)\n",
    "  data[i].loc[:, \"content\"].replace('[가-힣]+ 선임기자', \"\", regex=True, inplace=True)\n",
    "  data[i].loc[:, \"summary\"].replace('[가-힣]+ 선임기자', \"\", regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11d1c663-717a-47b2-a34e-7702bfeb5a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "  data[i].loc[(data[i][\"중요도(+/0/-)\"]==\"+\"), \"중요도(+/0/-)\"] = 1\n",
    "  data[i].loc[(data[i][\"중요도(+/0/-)\"]==\"0\"), \"중요도(+/0/-)\"] = 0\n",
    "  data[i].loc[(data[i][\"중요도(+/0/-)\"]==\"-\"), \"중요도(+/0/-)\"] = -1\n",
    "  data[i].loc[(data[i][\"극성값(+/0/-)\"]==\"+\"), \"극성값(+/0/-)\"] = 1\n",
    "  data[i].loc[(data[i][\"극성값(+/0/-)\"]==\"0\"), \"극성값(+/0/-)\"] = 0\n",
    "  data[i].loc[(data[i][\"극성값(+/0/-)\"]==\"-\"), \"극성값(+/0/-)\"] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d26c2f2f-b5cc-431e-baf8-cfbb446b5647",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "  data[i] = data[i].astype({\"중요도(+/0/-)\":int})\n",
    "  data[i] = data[i].astype({\"극성값(+/0/-)\":int})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57fd019-08d9-41dc-8f3c-52a063e764b1",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c3a5449-e4d9-4dde-8623-8f6d79d1acd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIRDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "      self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "      return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "      text = self.df.iloc[idx, 4]\n",
    "      label = self.df.iloc[idx, 7]\n",
    "      return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6225f469-b64e-46bf-bff7-4704280eed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = AIRDataset(data[0])\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_data = AIRDataset(data[1])\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4307ce-58fa-4188-9911-4ce5fca48df3",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcebef02-d198-4073-8b3b-05d69145528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FineTuneModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FineTuneModel, self).__init__()\n",
    "        self.linear = nn.Linear(768, 3, bias=False)\n",
    "        self.act = nn.Softmax(-1)\n",
    "    def forward(self, x):\n",
    "        result = self.linear(x)\n",
    "        return self.act(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "765020b5-ad0a-484d-9b12-d6256133680d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
      "The class this function is called from is 'KoBERTTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2db80321-cb6d-4d2a-b6ec-65ce22471592",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_model = BertModel.from_pretrained('skt/kobert-base-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75fa87c1-43a4-46d0-aaea-354cd8c1759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_model = FineTuneModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "408d33a0-ef2b-4cb2-8810-f8d4d728542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer = AdamP(tuning_model.parameters(), lr=1e-3, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9faf8f5-74a9-4ff2-9ec0-8c0b0c41c372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7694009ae7024adcb7cc772bd729473e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc9d1d76683491984455016ed27cded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3])\n"
     ]
    }
   ],
   "source": [
    "tuning_model.train()\n",
    "for epoch in tqdm.notebook.tqdm(range(epochs)):\n",
    "  optimizer.zero_grad()\n",
    "  for train, label in tqdm.notebook.tqdm(train_dataloader):\n",
    "    train = [tokenizer.batch_encode_plus([t[:min(len(t), max_len-2)]]) for t in train]\n",
    "    tokenized_train = [t[\"input_ids\"][0]+[1]*(max(0, max_len-len(t[\"input_ids\"][0]))) for t in train]\n",
    "    tokenized_train = torch.LongTensor(tokenized_train)\n",
    "    tokenized_train, label = tokenized_train.to(device), label.to(device)\n",
    "    attention_mask = [t[\"attention_mask\"][0]+[1]*(max(0, max_len-len(t[\"attention_mask\"][0]))) for t in train]\n",
    "    attention_mask, token_type = torch.LongTensor(attention_mask).to(device), torch.LongTensor(token_type).to(device)\n",
    "    pretrain_data = pretrain_model(input_ids=tokenized_train, attention_mask=attention_mask)\n",
    "    for_train_data = pretrain_data.pooler_output.data\n",
    "    output = tuning_model(for_train_data)\n",
    "    print(output.shape)\n",
    "    break\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dec3a344-38ab-405a-b51e-fa7757d7d63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(output, dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efca59aa-437e-4789-b62b-111d900c0e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, -1, -1, -1,  1, -1, -1,  0, -1, -1, -1, -1,  0, -1, -1,  1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
